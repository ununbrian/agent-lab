
# Agent Lab â€” Project 2 (Memory Agent)

> Goal: Upgrade the research agent with **episodic memory** so it can reuse past results and avoid repeated web research for similar questions.

---

## What this project adds

ðŸ§  **Persistent memory (Qdrant)**
- Store each completed research result as a memory record:
  - query
  - final answer
  - sources (URLs)
- Uses vector embeddings for semantic search.

âš¡ **Bypass research on memory hit**
- On new query:
  - First search memory
  - If similar result exists â†’ return memory answer directly
  - Skip planner / research / summarize / critique
- Saves:
  - API calls
  - tokens
  - latency

ðŸ” **Write memory only on fresh research**
- If answer comes from memory:
  - Do NOT write again (avoid duplicates)
- Only store when:
  - A new full research cycle completes
  - `final` output is non-empty

---

## Workflow

```

memory_search
â†“
(memory hit?) â”€â”€ yes â”€â”€â†’ memory_answer â†’ END
â”‚
no
â†“
planner
â†“
rewrite_query
â†“
research
â†“
summarize
â†“
evidence_gate (retry if weak)
â†“
critique
â†“
refine
â†“
memory_write
â†“
END

````

---

## Tech Stack (added in Project 2)

- Qdrant (vector database, via Docker)
- sentence-transformers (all-MiniLM-L6-v2)
- qdrant-client
- LangGraph conditional routing

---

## Memory Design

Each memory entry contains:

```json
{
  "query": "ERC-8004 å° ETH å¹£åƒ¹å¯èƒ½æœ‰å’©å½±éŸ¿ï¼Ÿ",
  "answer": "...final refined answer...",
  "sources": [
    "https://eips.ethereum.org/EIPS/eip-8004",
    "https://github.com/erc-8004/erc-8004-contracts"
  ]
}
````

Stored as:

* vector = embedding(answer)
* payload = { query, answer, sources }

---

## Behavior

### First time:

```bash
python -m app.main "ERC-8004 å°ETHå¹£åƒ¹å¯èƒ½æœ‰å’©å½±éŸ¿ï¼Ÿ"
```

â†’ full research
â†’ result saved to memory

### Second time (similar question):

```bash
python -m app.main "ERC-8004 é‡é»žä¿‚å’©ï¼Ÿ"
```

â†’ memory hit
â†’ return stored answer
â†’ no web search
â†’ no retry loop

---

## Guarantees

* Never returns memory hit with empty answer
* Never stores empty answers into memory
* Research is only triggered when memory is missing or insufficient
* Output still follows:

  * cited bullets
  * limitations section
  * explicit sources

---

## Current State

* Project 0: Agent workflow skeleton âœ…
* Project 1: Evidence-based research agent âœ…
* Project 2: Memory agent with bypass logic âœ…

Current version â‰ˆ `v0.2`

---

## Next Direction (Project 3 options)

Possible upgrades:

* Semantic cache + merge new updates
* User profile memory (preferences, portfolio)
* Multi-agent roles (researcher / critic / planner)
* Long-term memory decay / scoring
* Tool routing based on task type

---

## Philosophy

Prompting teaches the model.
Workflow teaches the system.
Memory teaches the agent.

This project shifts the agent from:

> stateless LLM calls
> to:
> stateful research assistant with recall
