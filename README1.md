å› ç‚ºä½ ä¿‚ã€Œç›´æ¥ç”± GitHub / UI copy è½åšŸã€ï¼Œå•² **`bash / Copy code / txt` æ¨™ç±¤ä¿‚ GitHub UI æ³¨å…¥å˜…**ï¼Œå””ä¿‚ Markdown æœ¬èº«ï¼Œæ‰€ä»¥è®Šå’—åƒåœ¾å­—ã€‚

æˆ‘è€Œå®¶å¹«ä½  **é‚„åŸæˆ 100% æ­£ç¢ºã€ä¹¾æ·¨ã€å¯ copy-paste å˜… README.md**ã€‚
ğŸ‘‰ ä½ åªéœ€è¦ï¼š**ç”± `md åˆ° ` å…¨é¸ copyï¼Œè¦†è“‹ä½  README.md å…§å®¹ã€‚**

---

````md
# Agent Lab â€” Project 0 (Playground)

> Goal: Build a runnable, debuggable LangGraph agent skeleton  
> (research â†’ summarize â†’ critique â†’ refine), with clean structure and trace logs for every node.

---

## What you have now

âœ… A working LangGraph pipeline that runs end-to-end:

1. Planner  
2. Research (stub)  
3. Summarize  
4. Critique  
5. Refine (final output)  

âœ… Every step writes a JSONL trace into `app/logs/` so you can debug the graph like a backend workflow (not a black-box prompt).

âœ… Clean project structure designed for future upgrades:

- Real web search + citations  
- Memory layer (Qdrant)  
- Tool routing / multi-tool plans  
- Multi-agent orchestration  
- Retry + guardrails + scoring  

---

## Tech Stack

- Python (venv)  
- LangGraph + LangChain Core  
- OpenAI (ChatOpenAI)  
- Pydantic + dotenv  
- Rich (optional later)  

---

## Folder Structure

```txt
agent-lab/
 â”œâ”€ app/
 â”‚   â”œâ”€ graphs/           # LangGraph workflows
 â”‚   â”‚   â””â”€ research_loop.py
 â”‚   â”œâ”€ llm/              # LLM adapters
 â”‚   â”‚   â””â”€ openai_client.py
 â”‚   â”œâ”€ tools/            # Tools (search, shell, browser...)
 â”‚   â”‚   â””â”€ search_stub.py
 â”‚   â”œâ”€ types/            # Typed state definitions
 â”‚   â”‚   â””â”€ state.py
 â”‚   â”œâ”€ logs/             # JSONL traces per node execution
 â”‚   â”‚   â””â”€ logger.py
 â”‚   â”œâ”€ memory/           # reserved for Project 2 (Qdrant etc.)
 â”‚   â”œâ”€ config.py
 â”‚   â””â”€ main.py
 â”œâ”€ scripts/
 â”œâ”€ .env                  # local secrets (DO NOT COMMIT)
 â””â”€ .venv/                # local venv (DO NOT COMMIT)
````

---

## How to Run

### 1) Activate venv

```bash
source .venv/bin/activate
```

### 2) Create `.env`

```bash
OPENAI_API_KEY=YOUR_KEY
OPENAI_MODEL=gpt-4.1-mini
```

### 3) Run

```bash
python -m app.main "Pendle sPENDLE å°å¹£åƒ¹å¯èƒ½æœ‰å’©å½±éŸ¿ï¼Ÿ"
```

---

## Debug Traces

After running, check:

```bash
ls app/logs
```

You should see files like:

```txt
YYYYMMDD-HHMMSS-planner.jsonl
YYYYMMDD-HHMMSS-research.jsonl
YYYYMMDD-HHMMSS-summary.jsonl
YYYYMMDD-HHMMSS-critique.jsonl
YYYYMMDD-HHMMSS-final.jsonl
```

Each file contains JSON lines with node inputs/outputs.

---

## Current Limitation (Intentional)

* `web_search_stub()` is a stub, so URLs are placeholders.

---

## Next Milestone (Project 1)

Replace stub with:

* Real web search
* Citations
* Auto retry logic

